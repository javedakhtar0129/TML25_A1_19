{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:50:08.766534Z",
     "start_time": "2025-05-23T11:50:05.083968Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfcb6bceb1ea99c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:50:29.807459Z",
     "start_time": "2025-05-23T11:50:29.800412Z"
    }
   },
   "outputs": [],
   "source": [
    "### LOADING THE MODEL\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecba666babb3f3d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:50:54.530321Z",
     "start_time": "2025-05-23T11:50:54.345334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(weights=False)\n",
    "# model.fc = torch.nn.Linear(512, 44)\n",
    "\n",
    "# ckpt = torch.load(\"01_MIA.pt\", map_location=\"cpu\",weights_only=False)\n",
    "# model.load_state_dict(ckpt)\n",
    "# if isinstance(ckpt, dict):\n",
    "#     print(\"Top-level keys:\", ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a67535bc39336feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 118\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m         id_, img, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(index)\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m id_, img, label, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmembership[index]\n\u001b[0;32m---> 34\u001b[0m data: MembershipDataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./priv_out.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#### EXAMPLE SUBMISSION\u001b[39;00m\n\u001b[1;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     39\u001b[0m     {\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mids,\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mids)),\n\u001b[1;32m     42\u001b[0m     }\n\u001b[1;32m     43\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/serialization.py:1548\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[1;32m   1542\u001b[0m             opened_file,\n\u001b[1;32m   1543\u001b[0m             map_location,\n\u001b[1;32m   1544\u001b[0m             _weights_only_unpickler,\n\u001b[1;32m   1545\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1546\u001b[0m         )\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1548\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[1;32m   1550\u001b[0m     opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args\n\u001b[1;32m   1551\u001b[0m )\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 118\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "#### DATASETS\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "class MembershipDataset(TaskDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__(transform)\n",
    "        self.membership = []\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int, int]:\n",
    "        id_, img, label = super().__getitem__(index)\n",
    "        return id_, img, label, self.membership[index]\n",
    "\n",
    "\n",
    "data: MembershipDataset = torch.load(\"./priv_out.pt\")\n",
    "\n",
    "#### EXAMPLE SUBMISSION\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"ids\": data.ids,\n",
    "        \"score\": np.random.randn(len(data.ids)),\n",
    "    }\n",
    ")\n",
    "df.to_csv(\"test.csv\", index=None)\n",
    "\n",
    "response = requests.post(\"http://34.122.51.94:9090/mia\", files={\"file\": open(\"test.csv\", \"rb\")}, headers={\"token\": \"TOKEN\"})\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "#### LOADING THE MODEL\n",
    "\n",
    "mean = [0.2980, 0.2962, 0.2987]\n",
    "std = [0.2886, 0.2875, 0.2889]\n",
    "\n",
    "model = resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 44)\n",
    "ckpt = torch.load(\"./01_MIA.pt\", map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "#### DATASETS\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "class MembershipDataset(TaskDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__(transform)\n",
    "        self.membership = []\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int, int]:\n",
    "        id_, img, label = super().__getitem__(index)\n",
    "        return id_, img, label, self.membership[index]\n",
    "\n",
    "# Load dataset\n",
    "data: MembershipDataset = torch.load(\"./priv_out.pt\")\n",
    "\n",
    "# Set up preprocessing and device\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "data.transform = transform\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Enable gradients only for the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# DataLoader with small batch size to avoid OOM\n",
    "loader = DataLoader(data, batch_size=8, shuffle=False)\n",
    "\n",
    "# Feature extraction\n",
    "features = []\n",
    "ids = []\n",
    "\n",
    "for id_, imgs, labels, _ in tqdm(loader):\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    imgs.requires_grad = True\n",
    "\n",
    "    outputs = model(imgs)\n",
    "    loss = F.cross_entropy(outputs, labels, reduction='none')\n",
    "\n",
    "    # Compute gradients w.r.t. final layer\n",
    "    model.zero_grad()\n",
    "    grads = torch.autograd.grad(loss.sum(), model.fc.parameters(), retain_graph=False)\n",
    "    flat_grads = torch.cat([g.view(g.size(0), -1) for g in grads], dim=1)\n",
    "    grad_norms = flat_grads.norm(p=2, dim=1).detach().cpu().numpy()\n",
    "\n",
    "    # Loss and confidence\n",
    "    loss_vals = loss.detach().cpu().numpy()\n",
    "    conf_vals = F.softmax(outputs, dim=1).max(dim=1)[0].detach().cpu().numpy()\n",
    "\n",
    "    for i in range(len(id_)):\n",
    "        features.append([grad_norms[i], loss_vals[i], conf_vals[i]])\n",
    "        ids.append(id_[i])\n",
    "\n",
    "# Normalize and prepare attack model\n",
    "features = np.array(features)\n",
    "features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-8)\n",
    "labels = np.array(data.membership)\n",
    "\n",
    "# Train logistic regression attack model\n",
    "attack_model = LogisticRegression()\n",
    "attack_model.fit(features, labels)\n",
    "\n",
    "# Predict membership scores\n",
    "scores = attack_model.predict_proba(features)[:, 1]\n",
    "\n",
    "# Create submission\n",
    "df = pd.DataFrame({\n",
    "    \"ids\": ids,\n",
    "    \"score\": scores,\n",
    "})\n",
    "df.to_csv(\"test.csv\", index=None)\n",
    "\n",
    "# Submit to server\n",
    "response = requests.post(\"http://34.122.51.94:9090/mia\", files={\"file\": open(\"test.csv\", \"rb\")}, headers={\"token\": \"TOKEN\"})\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
